"""
ì‹ì•½ì²˜ ë°”ì½”ë“œ ìµœì í™” ë§¤ì¹­
- ì „ìˆ˜ ë¹„êµ ê¸ˆì§€
- ì œì¡°ì‚¬ + í† í° ì¸ë±ìŠ¤ í™œìš©
- í›„ë³´ ì¶•ì†Œ í›„ fuzzy matching
"""

import asyncio
import asyncpg
import requests
import json
import time
import re
from typing import List, Dict, Optional

API_KEY = "14588a0a32f2476a8797"
API_BASE = "http://openapi.foodsafetykorea.go.kr/api"
SERVICE_NAME = "I2570"

def normalize_text(text):
    """í…ìŠ¤íŠ¸ ì •ê·œí™”"""
    if not text:
        return ""
    normalized = text.lower().strip()
    normalized = re.sub(r'\([^)]*\)', '', normalized)
    normalized = re.sub(r'\[[^\]]*\]', '', normalized)
    normalized = re.sub(r'\d+\.?\d*(g|ml|kg|l|mg|ê°œ|ì…|ea|EA)', '', normalized)
    normalized = re.sub(r'[^\wê°€-í£]', '', normalized)
    return normalized

def extract_tokens(text):
    """ì˜ë¯¸ ìˆëŠ” í† í° ì¶”ì¶œ"""
    if not text:
        return []
    normalized = normalize_text(text)
    tokens = []
    korean_tokens = re.findall(r'[ê°€-í£]{2,}', normalized)
    tokens.extend(korean_tokens)
    english_tokens = re.findall(r'[a-z]{3,}', normalized)
    tokens.extend(english_tokens)
    tokens = [t for t in tokens if not t.isdigit()]
    return list(set(tokens))

def token_overlap_score(tokens1: List[str], tokens2: List[str]) -> float:
    """í† í° ê²¹ì¹¨ ë¹„ìœ¨"""
    if not tokens1 or not tokens2:
        return 0.0
    set1 = set(tokens1)
    set2 = set(tokens2)
    intersection = len(set1 & set2)
    union = len(set1 | set2)
    return intersection / union if union > 0 else 0.0

def string_similarity(a: str, b: str) -> float:
    """ê°„ë‹¨í•œ ë¬¸ìì—´ ìœ ì‚¬ë„ (trigram ë°©ì‹)"""
    if not a or not b:
        return 0.0

    # 3-gram ìƒì„±
    def trigrams(s):
        s = f"  {s} "  # íŒ¨ë”©
        return [s[i:i+3] for i in range(len(s)-2)]

    tri_a = set(trigrams(a))
    tri_b = set(trigrams(b))

    if not tri_a or not tri_b:
        return 0.0

    intersection = len(tri_a & tri_b)
    union = len(tri_a | tri_b)

    return intersection / union if union > 0 else 0.0

async def find_candidates(
    conn,
    mfds_name_norm: str,
    mfds_company_norm: str,
    mfds_tokens: List[str]
) -> List[Dict]:
    """í›„ë³´ ì œí’ˆ ì°¾ê¸° (ì¸ë±ìŠ¤ í™œìš©)"""

    candidates = []

    # 1ì°¨ í›„ë³´: ì œì¡°ì‚¬ ì¼ì¹˜
    if mfds_company_norm:
        mfg_matches = await conn.fetch("""
            SELECT id, name, name_norm, manufacturer, manufacturer_norm, tokens
            FROM foods
            WHERE manufacturer_norm = $1
            LIMIT 50
        """, mfds_company_norm)
        candidates.extend([dict(r) for r in mfg_matches])

    # 2ì°¨ í›„ë³´: í† í° ê²¹ì¹¨ (ì œì¡°ì‚¬ ì¼ì¹˜ ì—†ì„ ë•Œ)
    if len(candidates) < 5 and mfds_tokens:
        token_matches = await conn.fetch("""
            SELECT id, name, name_norm, manufacturer, manufacturer_norm, tokens
            FROM foods
            WHERE tokens && $1
            ORDER BY array_length(tokens, 1) DESC
            LIMIT 50
        """, mfds_tokens)

        # ì¤‘ë³µ ì œê±°
        existing_ids = {c['id'] for c in candidates}
        for row in token_matches:
            if row['id'] not in existing_ids:
                candidates.append(dict(row))
                existing_ids.add(row['id'])

    # 3ì°¨ í›„ë³´: pg_trgm ìœ ì‚¬ë„ (ìœ„ ë°©ë²•ìœ¼ë¡œ ì°¾ì§€ ëª»í–ˆì„ ë•Œ)
    if len(candidates) < 5 and mfds_name_norm:
        # pg_trgm similarity threshold
        similarity_matches = await conn.fetch("""
            SELECT id, name, name_norm, manufacturer, manufacturer_norm, tokens,
                   similarity(name_norm, $1) as sim
            FROM foods
            WHERE similarity(name_norm, $1) > 0.3
            ORDER BY sim DESC
            LIMIT 50
        """, mfds_name_norm)

        existing_ids = {c['id'] for c in candidates}
        for row in similarity_matches:
            if row['id'] not in existing_ids:
                candidates.append(dict(row))
                existing_ids.add(row['id'])

    return candidates[:50]  # ìµœëŒ€ 50ê°œë¡œ ì œí•œ

async def match_product(
    conn,
    barcode: str,
    mfds_name: str,
    mfds_company: str
) -> Optional[Dict]:
    """ì œí’ˆ ë§¤ì¹­ (ìµœì í™”)"""

    # ì´ë¯¸ ë°”ì½”ë“œê°€ ìˆìœ¼ë©´ ìŠ¤í‚µ
    existing = await conn.fetchval(
        "SELECT id FROM foods WHERE barcode = $1",
        barcode
    )
    if existing:
        return None

    # ì •ê·œí™”
    mfds_name_norm = normalize_text(mfds_name)
    mfds_company_norm = normalize_text(mfds_company)
    mfds_tokens = extract_tokens(mfds_name)

    if not mfds_name_norm:
        return None

    # í›„ë³´ ì°¾ê¸° (ì¸ë±ìŠ¤ í™œìš©)
    candidates = await find_candidates(conn, mfds_name_norm, mfds_company_norm, mfds_tokens)

    if not candidates:
        return {
            'barcode': barcode,
            'food_id': None,
            'mfds_name': mfds_name,
            'mfds_company': mfds_company,
            'confidence': 0.0,
            'status': 'FAIL'
        }

    # ìµœê³  ì ìˆ˜ ì°¾ê¸°
    best_match = None
    best_score = 0.0

    for candidate in candidates:
        # ì´ë¦„ ìœ ì‚¬ë„
        name_sim = string_similarity(mfds_name_norm, candidate['name_norm'])

        # í† í° ê²¹ì¹¨
        token_overlap = token_overlap_score(mfds_tokens, candidate['tokens'] or [])

        # ì œì¡°ì‚¬ ë³´ë„ˆìŠ¤
        mfg_bonus = 0.0
        if mfds_company_norm and candidate['manufacturer_norm']:
            if mfds_company_norm == candidate['manufacturer_norm']:
                mfg_bonus = 0.2
            elif mfds_company_norm in candidate['manufacturer_norm'] or \
                 candidate['manufacturer_norm'] in mfds_company_norm:
                mfg_bonus = 0.1

        # ìµœì¢… ì ìˆ˜
        final_score = 0.5 * name_sim + 0.3 * token_overlap + 0.2 * mfg_bonus

        if final_score > best_score:
            best_score = final_score
            best_match = candidate

    # ìƒíƒœ ê²°ì •
    if best_score >= 0.85:
        status = 'AUTO'
    elif best_score >= 0.65:
        status = 'REVIEW'
    else:
        status = 'FAIL'

    return {
        'barcode': barcode,
        'food_id': best_match['id'] if best_match else None,
        'food_name': best_match['name'] if best_match else None,
        'mfds_name': mfds_name,
        'mfds_company': mfds_company,
        'confidence': best_score,
        'status': status
    }

def fetch_mfds_page(start_idx=1, end_idx=1000):
    """ì‹ì•½ì²˜ ìœ í†µë°”ì½”ë“œ API í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸°"""
    url = f"{API_BASE}/{API_KEY}/{SERVICE_NAME}/json/{start_idx}/{end_idx}"

    try:
        res = requests.get(url, timeout=30)
        data = res.json()

        if SERVICE_NAME not in data:
            return [], 0

        service_data = data[SERVICE_NAME]

        if 'RESULT' in service_data:
            result = service_data['RESULT']
            if result.get('CODE') != 'INFO-000':
                return [], 0

        total_count = int(service_data.get('total_count', 0))
        items = service_data.get('row', [])

        return items, total_count

    except Exception as e:
        print(f"âŒ API ì˜¤ë¥˜: {e}")
        return [], 0

async def main():
    conn = await asyncpg.connect('postgresql://stopper:stopper2026@localhost:5433/stopper')

    print("ğŸš€ ìµœì í™”ëœ ì‹ì•½ì²˜ ë°”ì½”ë“œ ë§¤ì¹­ ì‹œì‘\n")

    # ì •ê·œí™” í™•ì¸
    normalized_count = await conn.fetchval(
        "SELECT COUNT(*) FROM foods WHERE name_norm IS NOT NULL"
    )
    total_count = await conn.fetchval("SELECT COUNT(*) FROM foods")

    print(f"ğŸ“Š STOPPER DB ì •ê·œí™” ìƒíƒœ: {normalized_count:,}/{total_count:,}")

    if normalized_count < total_count * 0.5:
        print("âš ï¸  ë°ì´í„° ì •ê·œí™”ê°€ 50% ë¯¸ë§Œì…ë‹ˆë‹¤. normalize_existing_data.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.\n")
        await conn.close()
        return
    elif normalized_count < total_count * 0.9:
        print(f"âš ï¸  ì¼ë¶€ ì œí’ˆë§Œ ì •ê·œí™”ë¨ ({normalized_count*100//total_count}%). ë§¤ì¹­ ì •í™•ë„ê°€ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n")

    # ì‹ì•½ì²˜ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
    print("\nğŸ“¥ ì‹ì•½ì²˜ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘...\n")

    all_items = []
    page_size = 1000

    first_items, total_mfds = fetch_mfds_page(1, page_size)

    if total_mfds == 0:
        print("âŒ ì‹ì•½ì²˜ ë°ì´í„° ì—†ìŒ")
        await conn.close()
        return

    print(f"ğŸ“Š ì „ì²´ ì‹ì•½ì²˜ ë°ì´í„°: {total_mfds:,}ê°œ\n")
    all_items.extend(first_items)

    # ìµœëŒ€ 50,000ê°œ
    max_items = min(total_mfds, 50000)
    num_pages = (max_items + page_size - 1) // page_size

    for page in range(2, num_pages + 1):
        start_idx = (page - 1) * page_size + 1
        end_idx = min(page * page_size, max_items)

        items, _ = fetch_mfds_page(start_idx, end_idx)
        if not items:
            break

        all_items.extend(items)

        if page % 10 == 0:
            print(f"  ë‹¤ìš´ë¡œë“œ: {len(all_items):,}/{max_items:,}")

        time.sleep(0.2)

    print(f"\nâœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {len(all_items):,}ê°œ\n")

    # ë°”ì½”ë“œ ë§¤ì¹­
    print("ğŸ” ìµœì í™”ëœ ë§¤ì¹­ ì‹œì‘...\n")

    matches = []
    auto_count = 0
    review_count = 0
    fail_count = 0

    for i, item in enumerate(all_items, 1):
        barcode = item.get('BRCD_NO', '').strip()
        name = item.get('PRDT_NM', '').strip()
        company = item.get('CMPNY_NM', '').strip()

        if not barcode or not name:
            continue

        match = await match_product(conn, barcode, name, company)

        if match:
            matches.append(match)

            if match['status'] == 'AUTO':
                auto_count += 1
            elif match['status'] == 'REVIEW':
                review_count += 1
            else:
                fail_count += 1

        if i % 500 == 0:
            print(f"  ì§„í–‰: {i:,}/{len(all_items):,} | AUTO: {auto_count} | REVIEW: {review_count} | FAIL: {fail_count}")

    print(f"\nâœ… ë§¤ì¹­ ì™„ë£Œ\n")
    print(f"ğŸ“Š ê²°ê³¼:")
    print(f"  - AUTO (â‰¥85%): {auto_count:,}ê°œ")
    print(f"  - REVIEW (65-85%): {review_count:,}ê°œ")
    print(f"  - FAIL (<65%): {fail_count:,}ê°œ\n")

    # barcode_matches í…Œì´ë¸”ì— ì €ì¥
    print("ğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...")

    for match in matches:
        await conn.execute("""
            INSERT INTO barcode_matches (barcode, food_id, mfds_name, mfds_company, confidence, status)
            VALUES ($1, $2, $3, $4, $5, $6)
        """, match['barcode'], match['food_id'], match['mfds_name'],
             match['mfds_company'], match['confidence'], match['status'])

    print(f"âœ… {len(matches):,}ê°œ ì €ì¥ ì™„ë£Œ\n")

    # AUTO ë§¤ì¹­ë§Œ ì‹¤ì œ ë°”ì½”ë“œ ì—…ë°ì´íŠ¸
    print("ğŸ’¾ AUTO ë§¤ì¹­ ë°”ì½”ë“œ ì—…ë°ì´íŠ¸ ì¤‘...")

    auto_matches = [m for m in matches if m['status'] == 'AUTO']
    updated = 0

    for match in auto_matches:
        if match['food_id']:
            await conn.execute(
                "UPDATE foods SET barcode = $1 WHERE id = $2",
                match['barcode'], match['food_id']
            )
            updated += 1

    print(f"âœ… {updated:,}ê°œ ë°”ì½”ë“œ ì—…ë°ì´íŠ¸ ì™„ë£Œ\n")

    # ìµœì¢… í†µê³„
    total_barcodes = await conn.fetchval("SELECT COUNT(*) FROM foods WHERE barcode IS NOT NULL")
    print(f"ğŸ“Š ìµœì¢… ë°”ì½”ë“œ ë³´ìœ  ì œí’ˆ: {total_barcodes:,}ê°œ")

    # JSON ì €ì¥
    output_file = '/Users/js/Documents/stopper/data/mfds_barcode_matches_optimized.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(matches, f, ensure_ascii=False, indent=2)

    print(f"ğŸ’¾ ë§¤ì¹­ ê²°ê³¼ ì €ì¥: {output_file}\n")

    # AUTO ë§¤ì¹­ ìƒ˜í”Œ
    auto_samples = await conn.fetch("""
        SELECT f.name, f.barcode, bm.mfds_name, bm.confidence
        FROM barcode_matches bm
        JOIN foods f ON f.id = bm.food_id
        WHERE bm.status = 'AUTO'
        ORDER BY bm.confidence DESC
        LIMIT 20
    """)

    print("ğŸ“Š AUTO ë§¤ì¹­ ìƒ˜í”Œ (ìƒìœ„ 20ê°œ):")
    for s in auto_samples:
        print(f"  [{s['confidence']:.2f}] {s['name'][:30]:30s} â†” {s['mfds_name'][:30]:30s} | {s['barcode']}")

    await conn.close()

if __name__ == '__main__':
    asyncio.run(main())
